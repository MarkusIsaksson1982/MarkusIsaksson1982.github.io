I'll create a comprehensive Python script for extracting and parsing Swedish curriculum documents. This solution uses both PyMuPDF and pdfplumber for flexibility, and includes all the requested features.

```python
#!/usr/bin/env python3
"""
Swedish Curriculum Document Parser
Extracts and parses Skolverket curriculum documents with grade level categorization
and cross-subject bridge identification.
"""

import json
import csv
import re
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict, field
from datetime import datetime
import hashlib

import fitz  # PyMuPDF
import pdfplumber
from pdfplumber.page import Page
import yaml

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class CompetencyDescriptor:
    """Represents a competency descriptor from kunskapskrav"""
    grade_level: str  # E, C, or A
    text: str
    keywords: List[str] = field(default_factory=list)
    page_number: int = 0
    confidence_score: float = 0.0


@dataclass
class SubjectBridge:
    """Represents a connection to another subject"""
    target_subject: str
    connection_type: str  # 'thematic', 'skill', 'content'
    keywords_matched: List[str]
    strength: float  # 0.0 to 1.0


@dataclass
class KunskapskravSection:
    """Represents a complete kunskapskrav section"""
    subject: str
    year_level: str
    descriptors: Dict[str, List[CompetencyDescriptor]]  # Grouped by grade
    bridges: List[SubjectBridge]
    raw_text: str
    extraction_date: str


class ConfigManager:
    """Manages configuration for subject bridges and keyword mappings"""
    
    def __init__(self, config_path: str = "config.yaml"):
        self.config_path = Path(config_path)
        self.config = self.load_config()
        
    def load_config(self) -> Dict:
        """Load configuration from YAML file"""
        if not self.config_path.exists():
            self.create_default_config()
        
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.error(f"Failed to load config: {e}")
            return self.get_default_config()
    
    def get_default_config(self) -> Dict:
        """Return default configuration"""
        return {
            'languages': ['sv', 'en'],
            'grade_patterns': {
                'E': [r'betyget\s+E', r'för\s+E', r'nivå\s+E', r'grade\s+E'],
                'C': [r'betyget\s+C', r'för\s+C', r'nivå\s+C', r'grade\s+C'],
                'A': [r'betyget\s+A', r'för\s+A', r'nivå\s+A', r'grade\s+A']
            },
            'subject_bridges': {
                'Svenska': {
                    'keywords': ['språk', 'kommunikation', 'text', 'läsning', 'skrivning',
                                'berättande', 'argumentation', 'källkritik'],
                    'connection_types': ['linguistic', 'communication', 'literacy']
                },
                'Historia': {
                    'keywords': ['historisk', 'utveckling', 'förändring', 'kontinuitet',
                                'källkritik', 'tid', 'epok', 'samhälle'],
                    'connection_types': ['historical', 'temporal', 'societal']
                },
                'Samhällskunskap': {
                    'keywords': ['demokrati', 'rättigheter', 'samhälle', 'politik',
                                'ekonomi', 'hållbar', 'medborgar', 'makt'],
                    'connection_types': ['civic', 'societal', 'political']
                }
            },
            'extraction_settings': {
                'min_text_length': 20,
                'confidence_threshold': 0.5,
                'use_ocr_fallback': True
            }
        }
    
    def create_default_config(self):
        """Create a default configuration file"""
        with open(self.config_path, 'w', encoding='utf-8') as f:
            yaml.dump(self.get_default_config(), f, allow_unicode=True, indent=2)
        logger.info(f"Created default config at {self.config_path}")


class CurriculumParser:
    """Main parser for Swedish curriculum documents"""
    
    def __init__(self, config_manager: Optional[ConfigManager] = None):
        self.config_manager = config_manager or ConfigManager()
        self.config = self.config_manager.config
        
    def extract_text_pymupdf(self, pdf_path: str) -> Tuple[str, List[Dict]]:
        """Extract text using PyMuPDF"""
        text_content = []
        page_data = []
        
        try:
            doc = fitz.open(pdf_path)
            for page_num, page in enumerate(doc, 1):
                page_text = page.get_text()
                text_content.append(page_text)
                page_data.append({
                    'page': page_num,
                    'text': page_text,
                    'method': 'pymupdf'
                })
            doc.close()
            return '\n'.join(text_content), page_data
        except Exception as e:
            logger.error(f"PyMuPDF extraction failed: {e}")
            return "", []
    
    def extract_text_pdfplumber(self, pdf_path: str) -> Tuple[str, List[Dict]]:
        """Extract text using pdfplumber"""
        text_content = []
        page_data = []
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages, 1):
                    page_text = page.extract_text() or ""
                    text_content.append(page_text)
                    page_data.append({
                        'page': page_num,
                        'text': page_text,
                        'method': 'pdfplumber'
                    })
            return '\n'.join(text_content), page_data
        except Exception as e:
            logger.error(f"pdfplumber extraction failed: {e}")
            return "", []
    
    def extract_text(self, pdf_path: str) -> Tuple[str, List[Dict]]:
        """Extract text using both methods and choose best result"""
        pymupdf_text, pymupdf_pages = self.extract_text_pymupdf(pdf_path)
        pdfplumber_text, pdfplumber_pages = self.extract_text_pdfplumber(pdf_path)
        
        # Choose the method that extracted more text
        if len(pymupdf_text) >= len(pdfplumber_text):
            logger.info("Using PyMuPDF extraction")
            return pymupdf_text, pymupdf_pages
        else:
            logger.info("Using pdfplumber extraction")
            return pdfplumber_text, pdfplumber_pages
    
    def identify_grade_sections(self, text: str) -> Dict[str, List[str]]:
        """Identify and categorize text by grade levels (E/C/A)"""
        grade_sections = {'E': [], 'C': [], 'A': []}
        
        # Split text into paragraphs
        paragraphs = [p.strip() for p in text.split('\n') if p.strip()]
        
        current_grade = None
        current_section = []
        
        for para in paragraphs:
            # Check if this paragraph indicates a grade level
            grade_found = None
            for grade, patterns in self.config['grade_patterns'].items():
                for pattern in patterns:
                    if re.search(pattern, para, re.IGNORECASE):
                        grade_found = grade
                        break
                if grade_found:
                    break
            
            if grade_found:
                # Save previous section if exists
                if current_grade and current_section:
                    grade_sections[current_grade].extend(current_section)
                
                # Start new section
                current_grade = grade_found
                current_section = [para]
            elif current_grade:
                # Add to current section
                current_section.append(para)
        
        # Save final section
        if current_grade and current_section:
            grade_sections[current_grade].extend(current_section)
        
        return grade_sections
    
    def extract_keywords(self, text: str) -> List[str]:
        """Extract keywords from text for bridge matching"""
        # Simple keyword extraction - can be enhanced with NLP
        words = re.findall(r'\b\w+\b', text.lower())
        # Filter common Swedish stop words
        stop_words = {'och', 'i', 'att', 'det', 'som', 'på', 'av', 'för', 'med', 
                     'till', 'den', 'en', 'ett', 'är', 'var', 'har'}
        keywords = [w for w in words if w not in stop_words and len(w) > 3]
        return list(set(keywords))[:20]  # Return top 20 unique keywords
    
    def calculate_bridge_strength(self, keywords: List[str], 
                                 bridge_keywords: List[str]) -> float:
        """Calculate connection strength between subjects"""
        if not keywords or not bridge_keywords:
            return 0.0
        
        matches = sum(1 for kw in keywords if any(
            bkw in kw or kw in bkw for bkw in bridge_keywords
        ))
        return min(matches / len(bridge_keywords), 1.0)
    
    def identify_bridges(self, text: str, keywords: List[str]) -> List[SubjectBridge]:
        """Identify connections to other subjects"""
        bridges = []
        
        for subject, subject_config in self.config['subject_bridges'].items():
            bridge_keywords = subject_config['keywords']
            strength = self.calculate_bridge_strength(keywords, bridge_keywords)
            
            if strength > self.config['extraction_settings']['confidence_threshold']:
                matched_keywords = [kw for kw in keywords if any(
                    bkw in kw or kw in bkw for bkw in bridge_keywords
                )]
                
                bridge = SubjectBridge(
                    target_subject=subject,
                    connection_type=subject_config['connection_types'][0],
                    keywords_matched=matched_keywords[:5],
                    strength=strength
                )
                bridges.append(bridge)
        
        return sorted(bridges, key=lambda b: b.strength, reverse=True)
    
    def parse_kunskapskrav(self, text: str, subject: str = "Unknown", 
                          year_level: str = "Unknown") -> KunskapskravSection:
        """Parse kunskapskrav section from text"""
        grade_sections = self.identify_grade_sections(text)
        descriptors = {}
        
        for grade, sections in grade_sections.items():
            descriptors[grade] = []
            for section_text in sections:
                if len(section_text) < self.config['extraction_settings']['min_text_length']:
                    continue
                
                keywords = self.extract_keywords(section_text)
                descriptor = CompetencyDescriptor(
                    grade_level=grade,
                    text=section_text,
                    keywords=keywords,
                    confidence_score=0.8  # Can be calculated based on extraction quality
                )
                descriptors[grade].append(descriptor)
        
        # Extract overall keywords for bridge identification
        all_keywords = self.extract_keywords(text)
        bridges = self.identify_bridges(text, all_keywords)
        
        return KunskapskravSection(
            subject=subject,
            year_level=year_level,
            descriptors=descriptors,
            bridges=bridges,
            raw_text=text,
            extraction_date=datetime.now().isoformat()
        )
    
    def parse_document(self, pdf_path: str, subject: str = "Unknown", 
                      year_level: str = "Unknown") -> Optional[KunskapskravSection]:
        """Parse a complete curriculum document"""
        try:
            logger.info(f"Parsing document: {pdf_path}")
            text, page_data = self.extract_text(pdf_path)
            
            if not text:
                logger.error("No text extracted from document")
                return None
            
            kunskapskrav = self.parse_kunskapskrav(text, subject, year_level)
            
            # Add page numbers to descriptors
            for grade, desc_list in ku
