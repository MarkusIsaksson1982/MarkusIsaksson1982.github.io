<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title></title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<pre style="white-space: pre-wrap; font-family: sans-serif;">
---
Type: Python code artifact generated by Claude Sonnet 4 
Author: Claude Sonnet 4
File name: claude_streamlit_interactive_app.py
Keywords: [not added yet]
---

"""
Interactive ARTI Curriculum Assessment Tool - Streamlit Web Application
Collaborative creation: Grok 4 → Claude Sonnet 4 → ChatGPT-5 → Claude Sonnet 4

A browser-based tool for Swedish high school ARTI curriculum teaching and assessment.
Supports both Level 1 (ARTI1000X) and Level 2 (ARTI2000X) with interactive demos.

Usage: streamlit run arti_curriculum_tool_streamlit.py
"""

import streamlit as st
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris, load_wine, load_digits
from sklearn.model_selection import train_test_split, cross_val_score, learning_curve
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
import random
from typing import Dict, List, Tuple, Any

# Configure page
st.set_page_config(
    page_title="ARTI Curriculum Tool",
    page_icon="🤖",
    layout="wide",
    initial_sidebar_state="expanded"
)

class ARTIStreamlitTool:
    """Enhanced ARTI tool with Streamlit interface"""
    
    def __init__(self):
        if 'models' not in st.session_state:
            st.session_state.models = {}
        if 'results' not in st.session_state:
            st.session_state.results = {}
        
        self.curriculum_data = self._load_curriculum_structure()
        self.datasets = self._load_available_datasets()
        
    def _load_curriculum_structure(self) -> Dict[str, Any]:
        """Load ARTI curriculum structure"""
        return {
            "ARTI1000X": {
                "level": "Level 1 - Foundation",
                "topics": [
                    "AI Definitions and Basic Concepts",
                    "Data Quality and AI Accuracy", 
                    "Classification and Decision Trees",
                    "Supervised vs Unsupervised Learning",
                    "Ethical Implications and Bias",
                    "AI Applications in Society"
                ],
                "practical_skills": [
                    "Simple classification tasks",
                    "Basic data analysis", 
                    "Decision tree interpretation",
                    "Ethical reasoning"
                ]
            },
            "ARTI2000X": {
                "level": "Level 2 - Advanced",
                "topics": [
                    "Neural Networks and Deep Learning",
                    "Advanced Applications (Healthcare, Transport)",
                    "Risk Assessment and Safety",
                    "Advanced Ethics and Regulation",
                    "AI System Design"
                ],
                "practical_skills": [
                    "Neural network implementation",
                    "Complex problem solving",
                    "System evaluation", 
                    "Advanced ethical analysis"
                ]
            }
        }
    
    def _load_available_datasets(self) -> Dict[str, Any]:
        """Load available datasets for demonstrations"""
        return {
            "iris": {
                "name": "Iris Flowers",
                "description": "Classic dataset for learning classification",
                "loader": load_iris,
                "features": 4,
                "classes": 3,
                "bias_level": "Low"
            },
            "wine": {
                "name": "Wine Quality",
                "description": "Wine classification by chemical properties",
                "loader": load_wine,
                "features": 13,
                "classes": 3,
                "bias_level": "Medium"
            },
            "digits": {
                "name": "Handwritten Digits",
                "description": "Digit recognition (0-9)",
                "loader": lambda: load_digits(n_class=3),  # Limit to 3 classes for speed
                "features": 64,
                "classes": 3,
                "bias_level": "Medium"
            }
        }
    
    def load_dataset(self, dataset_name: str):
        """Load and prepare dataset"""
        dataset_info = self.datasets[dataset_name]
        data = dataset_info["loader"]()
        return data.data, data.target, data.feature_names if hasattr(data, 'feature_names') else None, data.target_names
    
    def plot_decision_boundary_2d(self, X, y, model, title="Decision Boundary"):
        """Create 2D decision boundary plot using PCA if needed"""
        if X.shape[1] > 2:
            pca = PCA(n_components=2)
            X_plot = pca.fit_transform(X)
        else:
            X_plot = X
            
        # Create mesh
        h = 0.02
        x_min, x_max = X_plot[:, 0].min() - 1, X_plot[:, 0].max() + 1
        y_min, y_max = X_plot[:, 1].min() - 1, X_plot[:, 1].max() + 1
        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                            np.arange(y_min, y_max, h))
        
        # Predict on mesh
        if X.shape[1] > 2:
            mesh_points = np.c_[xx.ravel(), yy.ravel()]
            mesh_points_orig = pca.inverse_transform(mesh_points)
            Z = model.predict(mesh_points_orig)
        else:
            Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
        
        Z = Z.reshape(xx.shape)
        
        # Create plotly figure
        fig = go.Figure()
        
        # Add decision boundary
        fig.add_trace(go.Contour(
            x=np.arange(x_min, x_max, h),
            y=np.arange(y_min, y_max, h),
            z=Z,
            showscale=False,
            opacity=0.3,
            colorscale='Viridis'
        ))
        
        # Add data points
        for i, class_name in enumerate(np.unique(y)):
            mask = y == i
            fig.add_trace(go.Scatter(
                x=X_plot[mask, 0],
                y=X_plot[mask, 1],
                mode='markers',
                name=f'Class {class_name}',
                marker=dict(size=8)
            ))
        
        fig.update_layout(
            title=title,
            xaxis_title="Component 1" if X.shape[1] > 2 else "Feature 1",
            yaxis_title="Component 2" if X.shape[1] > 2 else "Feature 2",
            height=400
        )
        
        return fig
    
    def create_confusion_matrix_plot(self, y_true, y_pred, class_names):
        """Create interactive confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        
        fig = px.imshow(
            cm,
            text_auto=True,
            aspect="auto",
            color_continuous_scale="Blues",
            title="Confusion Matrix"
        )
        
        fig.update_layout(
            xaxis_title="Predicted",
            yaxis_title="Actual",
            xaxis=dict(tickmode='array', tickvals=list(range(len(class_names))), ticktext=class_names),
            yaxis=dict(tickmode='array', tickvals=list(range(len(class_names))), ticktext=class_names)
        )
        
        return fig
    
    def create_learning_curve_plot(self, model, X, y, title="Learning Curve"):
        """Create learning curve visualization"""
        train_sizes, train_scores, val_scores = learning_curve(
            model, X, y, cv=3, n_jobs=-1, 
            train_sizes=np.linspace(0.1, 1.0, 10)
        )
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=train_sizes,
            y=np.mean(train_scores, axis=1),
            mode='lines+markers',
            name='Training Score',
            error_y=dict(type='data', array=np.std(train_scores, axis=1))
        ))
        
        fig.add_trace(go.Scatter(
            x=train_sizes,
            y=np.mean(val_scores, axis=1),
            mode='lines+markers',
            name='Validation Score',
            error_y=dict(type='data', array=np.std(val_scores, axis=1))
        ))
        
        fig.update_layout(
            title=title,
            xaxis_title="Training Set Size",
            yaxis_title="Accuracy Score",
            height=400
        )
        
        return fig
    
    def demonstrate_unsupervised_learning(self, X, title="Clustering Analysis"):
        """Demonstrate K-means clustering for unsupervised learning"""
        # Use PCA for visualization if high-dimensional
        if X.shape[1] > 2:
            pca = PCA(n_components=2)
            X_plot = pca.fit_transform(X)
        else:
            X_plot = X
            
        # K-means clustering
        kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
        clusters = kmeans.fit_predict(X)
        
        fig = px.scatter(
            x=X_plot[:, 0],
            y=X_plot[:, 1],
            color=clusters.astype(str),
            title=title,
            labels={
                'x': 'Component 1' if X.shape[1] > 2 else 'Feature 1',
                'y': 'Component 2' if X.shape[1] > 2 else 'Feature 2',
                'color': 'Cluster'
            }
        )
        
        # Add cluster centers
        centers = kmeans.cluster_centers_
        if X.shape[1] > 2:
            centers_plot = centers  # Already in PCA space
        else:
            centers_plot = centers
            
        fig.add_trace(go.Scatter(
            x=centers_plot[:, 0],
            y=centers_plot[:, 1],
            mode='markers',
            marker=dict(
                size=15,
                symbol='x',
                color='red',
                line=dict(width=2)
            ),
            name='Centroids',
            showlegend=True
        ))
        
        return fig, clusters
    
    def generate_ethical_scenario(self, level: str, domain: str = None) -> Dict[str, Any]:
        """Generate dynamic ethical scenarios"""
        scenarios = {
            "ARTI1000X": {
                "education": {
                    "scenario": "A school uses AI to predict student performance based on demographics, previous grades, and family income.",
                    "questions": [
                        "What biases might exist in this training data?",
                        "How could this unfairly impact certain student groups?", 
                        "What safeguards should be implemented?",
                        "How does this relate to Swedish equality principles?"
                    ],
                    "learning_objectives": ["Understand data bias", "Recognize fairness issues", "Consider societal impact"]
                },
                "employment": {
                    "scenario": "A company uses AI to screen job applications, trained on hiring decisions from the past 10 years.",
                    "questions": [
                        "What historical biases might be perpetuated?",
                        "How does this relate to Swedish anti-discrimination laws?",
                        "What transparency should candidates have?",
                        "How can bias be measured and mitigated?"
                    ],
                    "learning_objectives": ["Historical bias recognition", "Legal compliance", "Transparency principles"]
                }
            },
            "ARTI2000X": {
                "healthcare": {
                    "scenario": "An AI diagnostic system trained primarily on Northern European patient data is deployed globally in underserved regions.",
                    "questions": [
                        "How might population differences affect diagnostic accuracy?",
                        "What are the risks of misdiagnosis across different ethnicities?",
                        "How should regulatory approval work for global deployment?",
                        "What additional testing protocols are needed?"
                    ],
                    "learning_objectives": ["Global deployment risks", "Population bias", "Regulatory frameworks", "Safety protocols"]
                },
                "autonomous_systems": {
                    "scenario": "An autonomous vehicle must choose between protecting its passenger or pedestrians in an unavoidable accident scenario.",
                    "questions": [
                        "How should AI systems make life-or-death decisions?",
                        "Who is legally responsible for AI decisions?",
                        "How do cultural values influence these choices?",
                        "What testing is required before deployment?"
                    ],
                    "learning_objectives": ["Moral reasoning in AI", "Legal responsibility", "Cultural considerations", "Safety validation"]
                }
            }
        }
        
        available_domains = list(scenarios[level].keys())
        domain = domain or random.choice(available_domains)
        
        return {
            "domain": domain,
            "level": level,
            **scenarios[level][domain]
        }
    
    def create_assessment_rubric(self, level: str) -> Dict[str, Any]:
        """Create comprehensive assessment rubric"""
        rubrics = {
            "ARTI1000X": {
                "criteria": {
                    "AI Understanding": {
                        "E": "Can define basic AI concepts and identify common applications in daily life",
                        "C": "Can explain AI techniques, compare with human intelligence, and understand data quality importance",
                        "A": "Can analyze AI systems comprehensively, reason about implications, and evaluate appropriateness for different tasks"
                    },
                    "Practical Implementation": {
                        "E": "Can run and modify simple AI code with guidance, interpret basic results",
                        "C": "Can independently implement classification solutions and explain model behavior",
                        "A": "Can design AI solutions for new problems, optimize parameters, and evaluate performance critically"
                    },
                    "Ethical Reasoning": {
                        "E": "Can identify basic ethical issues in AI applications",
                        "C": "Can analyze ethical implications, consider multiple stakeholders, and propose basic solutions",
                        "A": "Can evaluate complex ethical scenarios, consider legal frameworks, and design comprehensive mitigation strategies"
                    },
                    "Communication": {
                        "E": "Can present findings with basic explanations",
                        "C": "Can communicate AI concepts clearly to different audiences with appropriate examples",
                        "A": "Can lead discussions on AI topics, synthesize different perspectives, and argue positions effectively"
                    }
                }
            },
            "ARTI2000X": {
                "criteria": {
                    "Advanced AI Techniques": {
                        "E": "Understands neural networks and can implement basic versions",
                        "C": "Can compare different AI approaches and select appropriate methods",
                        "A": "Can design complex AI architectures and evaluate trade-offs systematically"
                    },
                    "Risk Assessment": {
                        "E": "Can identify risks in AI systems with guidance",
                        "C": "Can conduct structured risk assessments and propose mitigation strategies",
                        "A": "Can lead comprehensive risk analysis including societal, technical, and ethical dimensions"
                    },
                    "System Design": {
                        "E": "Can participate in AI system design with support",
                        "C": "Can design AI systems considering user needs and constraints",
                        "A": "Can architect complex AI solutions with full lifecycle considerations"
                    }
                }
            }
        }
        return rubrics.get(level, {})

def main():
    st.title("🤖 ARTI Curriculum Assessment Tool")
    st.markdown("*Collaborative AI Development: Grok 4 → Claude Sonnet 4 → ChatGPT-5 → Claude Sonnet 4*")
    
    # Initialize tool
    tool = ARTIStreamlitTool()
    
    # Sidebar configuration
    st.sidebar.header("Configuration")
    
    # Level selection
    level = st.sidebar.selectbox(
        "Select ARTI Level:",
        ["ARTI1000X", "ARTI2000X"],
        help="Choose the curriculum level for appropriate content complexity"
    )
    
    # Dataset selection  
    dataset_name = st.sidebar.selectbox(
        "Select Dataset:",
        list(tool.datasets.keys()),
        format_func=lambda x: tool.datasets[x]["name"]
    )
    
    # Display curriculum info
    st.sidebar.markdown(f"**{tool.curriculum_data[level]['level']}**")
    st.sidebar.markdown("**Topics:**")
    for topic in tool.curriculum_data[level]['topics']:
        st.sidebar.markdown(f"• {topic}")
    
    # Main content
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header(f"Classification Demo - {tool.datasets[dataset_name]['name']}")
        
        # Dataset info
        dataset_info = tool.datasets[dataset_name]
        st.info(f"**Dataset**: {dataset_info['description']} | **Features**: {dataset_info['features']} | **Classes**: {dataset_info['classes']} | **Bias Level**: {dataset_info['bias_level']}")
        
        # Load dataset
        X, y, feature_names, class_names = tool.load_dataset(dataset_name)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
        
        # Model parameters
        if level == "ARTI1000X":
            st.subheader("Decision Tree Parameters")
            max_depth = st.slider("Maximum Depth", 2, 10, 3, help="Controls model complexity and overfitting")
            min_samples_split = st.slider("Minimum Samples to Split", 2, 20, 5, help="Prevents overfitting by requiring minimum samples")
            
            if st.button("Train Decision Tree", type="primary"):
                # Train model
                model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
                
                # Display results
                st.success(f"**Accuracy: {accuracy:.3f}**")
                st.markdown("**Educational Note**: Decision trees create interpretable 'if-then' rules that students can follow and understand.")
                
                # Visualizations
                tab1, tab2, tab3 = st.tabs(["Decision Boundary", "Confusion Matrix", "Learning Curve"])
                
                with tab1:
                    fig = tool.plot_decision_boundary_2d(X_test, y_test, model, "Decision Tree - Decision Boundary")
                    st.plotly_chart(fig, use_container_width=True)
                
                with tab2:
                    fig = tool.create_confusion_matrix_plot(y_test, y_pred, class_names)
                    st.plotly_chart(fig, use_container_width=True)
                
                with tab3:
                    fig = tool.create_learning_curve_plot(model, X, y, "Decision Tree - Learning Curve")
                    st.plotly_chart(fig, use_container_width=True)
                
                # Store results
                st.session_state.results[level] = {
                    "model_type": "Decision Tree",
                    "accuracy": accuracy,
                    "interpretable": True,
                    "complexity": "Low to Medium"
                }
        
        elif level == "ARTI2000X":
            st.subheader("Model Comparison: Decision Tree vs Neural Network")
            
            # Parameters for both models
            col_dt, col_nn = st.columns(2)
            with col_dt:
                st.markdown("**Decision Tree**")
                dt_max_depth = st.slider("DT Max Depth", 3, 15, 5)
            with col_nn:
                st.markdown("**Neural Network**") 
                hidden_layers = st.selectbox("Hidden Layer Size", [(10, 5), (20, 10), (50, 25)], format_func=str)
                max_iter = st.slider("Max Iterations", 100, 2000, 1000, step=100)
            
            if st.button("Train Both Models", type="primary"):
                # Decision Tree
                dt_model = DecisionTreeClassifier(max_depth=dt_max_depth, random_state=42)
                dt_model.fit(X_train, y_train)
                dt_pred = dt_model.predict(X_test)
                dt_accuracy = accuracy_score(y_test, dt_pred)
                
                # Neural Network
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                
                nn_model = MLPClassifier(
                    hidden_layer_sizes=hidden_layers,
                    max_iter=max_iter,
                    random_state=42,
                    early_stopping=True
                )
                nn_model.fit(X_train_scaled, y_train)
                nn_pred = nn_model.predict(X_test_scaled)
                nn_accuracy = accuracy_score(y_test, nn_pred)
                
                # Results comparison
                results_df = pd.DataFrame({
                    'Model': ['Decision Tree', 'Neural Network'],
                    'Accuracy': [dt_accuracy, nn_accuracy],
                    'Interpretable': ['High', 'Low'],
                    'Complexity': ['Medium', 'High']
                })
                
                st.subheader("Model Comparison Results")
                st.dataframe(results_df, use_container_width=True)
                
                col_res1, col_res2 = st.columns(2)
                with col_res1:
                    st.metric("Decision Tree Accuracy", f"{dt_accuracy:.3f}")
                with col_res2:
                    st.metric("Neural Network Accuracy", f"{nn_accuracy:.3f}")
                
                st.markdown("**Educational Note**: Neural networks often achieve higher accuracy but sacrifice interpretability. This trade-off is crucial in AI system design.")
                
                # Visualizations
                tab1, tab2, tab3 = st.tabs(["Decision Boundaries", "Confusion Matrices", "Learning Curves"])
                
                with tab1:
                    col_vis1, col_vis2 = st.columns(2)
                    with col_vis1:
                        fig1 = tool.plot_decision_boundary_2d(X_test, y_test, dt_model, "Decision Tree")
                        st.plotly_chart(fig1, use_container_width=True)
                    with col_vis2:
                        fig2 = tool.plot_decision_boundary_2d(X_test_scaled, y_test, nn_model, "Neural Network")
                        st.plotly_chart(fig2, use_container_width=True)
                
                with tab2:
                    col_cm1, col_cm2 = st.columns(2)
                    with col_cm1:
                        fig3 = tool.create_confusion_matrix_plot(y_test, dt_pred, class_names)
                        st.plotly_chart(fig3, use_container_width=True)
                    with col_cm2:
                        fig4 = tool.create_confusion_matrix_plot(y_test, nn_pred, class_names)
                        st.plotly_chart(fig4, use_container_width=True)
                
                with tab3:
                    col_lc1, col_lc2 = st.columns(2)
                    with col_lc1:
                        fig5 = tool.create_learning_curve_plot(dt_model, X, y, "Decision Tree")
                        st.plotly_chart(fig5, use_container_width=True)
                    with col_lc2:
                        fig6 = tool.create_learning_curve_plot(nn_model, X, y, "Neural Network")
                        st.plotly_chart(fig6, use_container_width=True)
                
                # Store results
                st.session_state.results[level] = {
                    "models": {
                        "decision_tree": {"accuracy": dt_accuracy, "interpretable": True},
                        "neural_network": {"accuracy": nn_accuracy, "interpretable": False}
                    }
                }
        
        # Unsupervised Learning Demo (both levels)
        st.subheader("Unsupervised Learning: Clustering Analysis")
        st.markdown("*Discover hidden patterns in data without labeled examples*")
        
        if st.button("Run Clustering Analysis"):
            fig, clusters = tool.demonstrate_unsupervised_learning(X, f"K-Means Clustering - {dataset_info['name']}")
            st.plotly_chart(fig, use_container_width=True)
            st.info("**Educational Note**: Unsupervised learning finds patterns without knowing the 'right answers'. Compare the clusters with the actual classes!")
    
    with col2:
        st.header("Educational Materials")
        
        # Ethical Scenario
        st.subheader("🤔 Ethical Scenario")
        domain = st.selectbox("Choose Domain:", 
                             ["education", "employment"] if level == "ARTI1000X" else ["healthcare", "autonomous_systems"])
        
        if st.button("Generate Ethical Scenario"):
            scenario = tool.generate_ethical_scenario(level, domain)
            
            st.markdown(f"**Domain**: {scenario['domain'].title()}")
            st.markdown(f"**Scenario**: {scenario['scenario']}")
            
            st.markdown("**Discussion Questions:**")
            for i, question in enumerate(scenario['questions'], 1):
                st.markdown(f"{i}. {question}")
            
            st.markdown("**Learning Objectives:**")
            for obj in scenario['learning_objectives']:
                st.markdown(f"• {obj}")
        
        # Assessment Rubric
        st.subheader("📋 Assessment Rubric")
        if st.button("Show Rubric"):
            rubric = tool.create_assessment_rubric(level)
            
            for criterion, levels in rubric['criteria'].items():
                st.markdown(f"**{criterion}:**")
                for grade, description in levels.items():
                    st.markdown(f"• **{grade}**: {description}")
                st.markdown("---")
        
        # Student Exercise
        st.subheader("📝 Student Exercise")
        exercises = {
            "ARTI1000X": {
                "title": "Modify and Analyze",
                "tasks": [
                    "Change the decision tree depth and observe accuracy",
                    "Try the model on a different dataset",
                    "Identify potential biases in the data",
                    "Propose improvements to reduce bias"
                ]
            },
            "ARTI2000X": {
                "title": "Compare and Evaluate",
                "tasks": [
                    "Compare decision tree vs neural network performance",
                    "Analyze interpretability vs accuracy trade-offs", 
                    "Evaluate which model is better for different scenarios",
                    "Design a hybrid approach combining both methods"
                ]
            }
        }
        
        exercise = exercises[level]
        st.markdown(f"**{exercise['title']}**")
        for i, task in enumerate(exercise['tasks'], 1):
            st.markdown(f"{i}. {task}")
    
    # Generate Report
    st.header("📊 Session Report")
    if st.button("Generate Report"):
        if level in st.session_state.results:
            results = st.session_state.results[level]
            
            report = f"""
# ARTI {level} Session Report
**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Dataset**: {tool.datasets[dataset_name]['name']}

## Model Performance
"""
            if 'models' in results:
                for model_name, metrics in results['models'].items():
                    report += f"\n**{model_name.replace('_', ' ').title()}**: {metrics['accuracy']:.3f} accuracy"
            else:
                report += f"\n**{results.get('model_type', 'Model')}**: {results.get('accuracy', 'N/A')} accuracy"
            
            report += f"""

## Educational Insights
- **Level**: {tool.curriculum_data[level]['level']}
- **Focus**: {'Interpretability and basic concepts' if level == 'ARTI1000X' else 'Performance comparison and complexity'}
- **Dataset Bias Level**: {tool.datasets[dataset_name]['bias_level']}

## Recommendations
- {'Start with decision trees for clear understanding' if level == 'ARTI1000X' else 'Emphasize interpretability vs performance trade-offs'}
- Discuss ethical implications of AI in chosen domain
- Practice with different datasets to understand bias
- Connect technical concepts to societal impact
"""
            
            st.markdown(report)
            st.download_button("Download Report", report, f"arti_{level}_report_{datetime.now().strftime('%Y%m%d')}.md")
        else:
            st.warning("No results to report. Please run a model demonstration first.")

if __name__ == "__main__":
    main()  
</pre>
</body>
</html>
