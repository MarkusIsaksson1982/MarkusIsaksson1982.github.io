<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title></title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<pre style="white-space: pre-wrap; font-family: sans-serif;">
---
Type: Code artifact generated by ChatGPT-5 
Author: ChatGPT-5
File name(s): TicTacToeAI.jsx
Keywords: [not added yet]
---

import React, { useState, useEffect } from 'react';

// TicTacToeAI.jsx
// Single-file React component (Tailwind for styling) demonstrating a minimax AI.
// - Exports a default React component that can be dropped into a React app.
// - Includes UI controls for Human vs AI play, difficulty (perfect/imperfect),
//   and a simple "AI thinking" breakdown showing scores for candidate moves.
// - Teacher notes (below) explain how to use this in lessons.

// Teacher notes (keep in file for easy copy/paste into lesson plans):
// - Place this file under src/components/TicTacToeAI.jsx in a React + Tailwind project.
// - Usage: import TicTacToeAI from '@/components/TicTacToeAI'; then render <TicTacToeAI />.
// - Learning goals: search algorithms (minimax), decision-making, tradeoffs (perfect vs imperfect AI),
//   and ethics discussion prompts (see bottom of file).

const BOARD_SIZE = 3;
const EMPTY = '';
const PLAYER_X = 'X'; // human
const PLAYER_O = 'O'; // AI

function cloneBoard(board) {
  return board.map((r) => [...r]);
}

function checkWinner(board) {
  // rows & cols
  for (let i = 0; i < BOARD_SIZE; i++) {
    if (
      board[i][0] !== EMPTY &&
      board[i][0] === board[i][1] &&
      board[i][1] === board[i][2]
    ) {
      return board[i][0];
    }
    if (
      board[0][i] !== EMPTY &&
      board[0][i] === board[1][i] &&
      board[1][i] === board[2][i]
    ) {
      return board[0][i];
    }
  }
  // diagonals
  if (
    board[0][0] !== EMPTY &&
    board[0][0] === board[1][1] &&
    board[1][1] === board[2][2]
  ) {
    return board[0][0];
  }
  if (
    board[0][2] !== EMPTY &&
    board[0][2] === board[1][1] &&
    board[1][1] === board[2][0]
  ) {
    return board[0][2];
  }
  // draw?
  const flat = board.flat();
  if (flat.every((c) => c !== EMPTY)) return 'DRAW';
  return null;
}

// Minimax implementation returns { score, move } when called for root, or score for recursive calls
function minimax(board, depth, isMaximizing) {
  const winner = checkWinner(board);
  if (winner === PLAYER_O) return 10 - depth;
  if (winner === PLAYER_X) return depth - 10;
  if (winner === 'DRAW') return 0;

  if (isMaximizing) {
    let best = -Infinity;
    for (let r = 0; r < BOARD_SIZE; r++) {
      for (let c = 0; c < BOARD_SIZE; c++) {
        if (board[r][c] === EMPTY) {
          board[r][c] = PLAYER_O;
          const val = minimax(board, depth + 1, false);
          board[r][c] = EMPTY;
          best = Math.max(best, val);
        }
      }
    }
    return best;
  } else {
    let best = Infinity;
    for (let r = 0; r < BOARD_SIZE; r++) {
      for (let c = 0; c < BOARD_SIZE; c++) {
        if (board[r][c] === EMPTY) {
          board[r][c] = PLAYER_X;
          const val = minimax(board, depth + 1, true);
          board[r][c] = EMPTY;
          best = Math.min(best, val);
        }
      }
    }
    return best;
  }
}

function findBestMove(board) {
  let bestScore = -Infinity;
  let bestMove = null;
  const evaluations = [];
  for (let r = 0; r < BOARD_SIZE; r++) {
    for (let c = 0; c < BOARD_SIZE; c++) {
      if (board[r][c] === EMPTY) {
        board[r][c] = PLAYER_O;
        const score = minimax(board, 0, false);
        board[r][c] = EMPTY;
        evaluations.push({ r, c, score });
        if (score > bestScore) {
          bestScore = score;
          bestMove = { r, c };
        }
      }
    }
  }
  return { bestMove, evaluations };
}

export default function TicTacToeAI() {
  const emptyBoard = Array.from({ length: BOARD_SIZE }, () => Array(BOARD_SIZE).fill(EMPTY));
  const [board, setBoard] = useState(emptyBoard);
  const [currentPlayer, setCurrentPlayer] = useState(PLAYER_X);
  const [status, setStatus] = useState(null);
  const [evaluations, setEvaluations] = useState([]);
  const [showEvals, setShowEvals] = useState(true);
  const [imperfectAI, setImperfectAI] = useState(false);
  const [history, setHistory] = useState([]);

  useEffect(() => {
    const w = checkWinner(board);
    setStatus(w);
    if (!w && currentPlayer === PLAYER_O) {
      // AI turn
      // small timeout to let UI update
      const t = setTimeout(() => {
        const { bestMove, evaluations } = findBestMove(cloneBoard(board));
        setEvaluations(evaluations);
        let move = bestMove;
        if (imperfectAI && Math.random() < 0.35) {
          // 35% of the time pick a suboptimal move (teaching: imperfect AI)
          const empties = [];
          for (let r = 0; r < BOARD_SIZE; r++)
            for (let c = 0; c < BOARD_SIZE; c++) if (board[r][c] === EMPTY) empties.push({ r, c });
          if (empties.length) move = empties[Math.floor(Math.random() * empties.length)];
        }
        if (move) applyMove(move.r, move.c, PLAYER_O);
      }, 400);
      return () => clearTimeout(t);
    }
  }, [board, currentPlayer, imperfectAI]);

  function applyMove(r, c, player) {
    if (board[r][c] !== EMPTY) return false;
    const nb = cloneBoard(board);
    nb[r][c] = player;
    setHistory((h) => [...h, cloneBoard(board)]);
    setBoard(nb);
    setCurrentPlayer(player === PLAYER_X ? PLAYER_O : PLAYER_X);
    return true;
  }

  function handleCellClick(r, c) {
    if (status) return; // game over
    if (currentPlayer !== PLAYER_X) return; // not human's turn
    if (!applyMove(r, c, PLAYER_X)) return;
  }

  function resetGame() {
    setBoard(emptyBoard);
    setCurrentPlayer(PLAYER_X);
    setStatus(null);
    setEvaluations([]);
    setHistory([]);
  }

  function undo() {
    if (!history.length) return;
    const last = history[history.length - 1];
    setBoard(last);
    setHistory((h) => h.slice(0, -1));
    setCurrentPlayer(PLAYER_X);
    setStatus(null);
  }

  const winner = status;

  return (
    <div className="max-w-3xl mx-auto p-4">
      <h2 className="text-2xl font-semibold mb-2">Tic‑Tac‑Toe — Minimax AI Demo (ARTI)</h2>
      <div className="flex gap-4 flex-col md:flex-row">
        <div className="p-4 rounded-2xl shadow-md bg-white">
          <div className="grid grid-cols-3 gap-2">
            {board.map((row, r) =>
              row.map((cell, c) => (
                <button
                  key={`${r}-${c}`}
                  onClick={() => handleCellClick(r, c)}
                  className="w-20 h-20 md:w-24 md:h-24 flex items-center justify-center text-3xl font-bold rounded-lg border hover:bg-gray-50"
                >
                  {cell}
                </button>
              ))
            )}
          </div>

          <div className="mt-4 flex gap-2 items-center">
            <button onClick={resetGame} className="px-3 py-1 rounded bg-blue-500 text-white">Reset</button>
            <button onClick={undo} className="px-3 py-1 rounded border">Undo</button>
            <label className="flex items-center gap-2 ml-2">
              <input type="checkbox" checked={imperfectAI} onChange={(e) => setImperfectAI(e.target.checked)} />
              Imperfect AI (teaching mode)
            </label>
            <label className="flex items-center gap-2 ml-2">
              <input type="checkbox" checked={showEvals} onChange={(e) => setShowEvals(e.target.checked)} />
              Show AI move evaluations
            </label>
          </div>

          <div className="mt-3 text-sm text-gray-700">
            {winner ? (
              winner === 'DRAW' ? (
                <div>Game over: Draw.</div>
              ) : (
                <div>Game over: <strong>{winner}</strong> wins.</div>
              )
            ) : (
              <div>Turn: <strong>{currentPlayer}</strong></div>
            )}
          </div>
        </div>

        <div className="flex-1 p-4 rounded-2xl shadow-md bg-white">
          <h3 className="font-semibold">AI Thinking (candidate moves)</h3>
          <p className="text-sm text-gray-600">Minimax scores (higher = better for AI). Depth-sensitive scoring gives faster wins higher value.</p>

          {showEvals ? (
            <div className="mt-2">
              {evaluations.length === 0 ? (
                <div className="text-sm text-gray-500">Evaluations will appear when it's AI's turn or after a move.</div>
              ) : (
                <div className="grid grid-cols-1 gap-2">
                  {evaluations
                    .slice()
                    .sort((a, b) => b.score - a.score)
                    .map((ev, idx) => (
                      <div key={idx} className="flex justify-between items-center border rounded p-2">
                        <div>Move: ({ev.r}, {ev.c})</div>
                        <div className="font-mono">score: {ev.score}</div>
                      </div>
                    ))}
                </div>
              )}
            </div>
          ) : (
            <div className="text-sm text-gray-500 mt-2">Evaluations hidden.</div>
          )}

          <div className="mt-4">
            <h4 className="font-medium">Teacher prompts</h4>
            <ol className="list-decimal ml-5 text-sm text-gray-700 mt-2">
              <li>How does minimax evaluate moves? (explain maximizer/minimizer roles)</li>
              <li>Why might an "imperfect" AI feel more fun for humans?</li>
              <li>What tradeoffs exist between perfect play (minimax) and performance/complexity?</li>
              <li>Extension: implement alpha-beta pruning — how and why does it help?</li>
            </ol>
          </div>
        </div>
      </div>

      <div className="mt-4 p-4 rounded-2xl shadow-sm bg-white text-sm text-gray-700">
        <strong>Classroom exercise ideas</strong>
        <ul className="list-disc ml-5 mt-2">
          <li>Have students modify the scoring function to prefer corners. Discuss fairness and predictability.</li>
          <li>Time different strategies (minimax vs random) and chart results across many games.</li>
          <li>Build a visualization that draws the partial game tree for a selected move (student project).</li>
        </ul>
      </div>
    </div>
  );
}

/*
Additional notes for repository placement and filenames:
- Suggested path: /svsk/ai/arti-tictactoe/TicTacToeAI.jsx
- Commit message suggestion: "Add interactive TicTacToe minimax React component for ARTI curriculum"

Ethics discussion (copy into lesson):
- When an AI always plays perfectly, it may discourage learners. Ask: Is the goal to teach optimal play or to support learning progression?
- If we bias an AI (e.g., favor certain moves), who decides the bias and on what basis? How does that relate to fairness?
*/
  
</pre>  
</body>
</html>
